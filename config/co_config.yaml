# CO Configuration for co sub-system
routine:
  inference:
    schedule: [[1, 7, 1], [5, 18, 59]]
    max_check_time: 5
    start_file: 'start_co_inference_process.py'
  training:
    schedule: [[5, 19, 0], [1, 7, 0]]
    max_check_time: -1
    start_file: 'start_co_training_process.py'

inference:
  num_of_stage: 2
  log_level: 'debug'
  resampler:
    mininum_num_slice: 32
    target_spacing: [0.8, 0.8, 1.0]
  
  health_disk_space: 30 # GB, if the space of disk is less than this, then remove the oldest data
  num_data_removed_per_time: 100 # how many data be removed each time
  
training:
  num_of_stage: 2
  log_level: 'info'
  enable_custom_training: False

  data:
    num_training_series: [300, 600]
    num_validating_series: 120
    fixed_train_data: ''
    
  nodule_size_ranges: # pixel size
    benign: [0, 52] 
    probably_benign: [52, 176] 
    probably_suspicious: [176, 418]
    suspicious: [418, -1]

  connect_timeout: -1 # seconds
  secs_every_try: 60 # seconds

  envoy:
    director_host: 192.168.1.1
    director_port: 1029
    shard_name: COC
    tls: false
    root_certificate: ~
    private_key: ~
    certificate: ~

  post_process:
    use_best_model: False # use best of all of past models

  stage1:
    envoy: # envoy config for openfl
      params: 
        cuda_devices: []
        install_requirements: False
      optional_plugin_components: {}

      shard_descriptor:
        template: openfl_system.co_sub_system.fl_training.openfl_interface.CTShardDescriptor
        params:
          ct_shard_dataset: openfl_system.co_sub_system.fl_training.openfl_interface.CTShardDatasetStage1
          depth: 32
    custom_training:
      model_template: openfl_system.model.stage1_model
      logic_template: 
        train: openfl_system.train_val_logic.stage1_train_val.train_wrapper
        val: openfl_system.train_val_logic.stage1_train_val.validate
      optimizer: 
        template: tensorflow.keras.optimizers.Adam
        params:
          learning_rate: 0.0001
      num_epochs: 5
      batch_size: 1
      
  stage2:
    envoy: # envoy config for openfl
      params:
        cuda_devices: []
        install_requirements: False
      optional_plugin_components: {}

      shard_descriptor:
        template: openfl_system.co_sub_system.fl_training.openfl_interface.CTShardDescriptor
        params:
          ct_shard_dataset: openfl_system.co_sub_system.fl_training.openfl_interface.CTShardDatasetStage2
          crop_settings: {'large_shape':  [80, 80, 30],
                          'medium_shape': [60, 60, 20],
                          'small_shape':  [40, 40, 10], 
                          'final_shape':  [80, 80, 30, 1]}
          iou_threshold: 0.0
    custom_training:
      model_template: openfl_system.model.stage2_model
      logic_template: 
        train: openfl_system.train_val_logic.stage2_train_val.train_wrapper
        val: openfl_system.train_val_logic.stage2_train_val.validate
      optimizer:
        template: tensorflow.keras.optimizers.Adam
        params:
          learning_rate: 0.0005
      num_epochs: 10
      batch_size: 32